#! /g/ssli/sw/roylu/bin/python3
import os
import re
import sys
import time
import signal
import getpass
import htcondor
import tempfile
import datetime
import argparse
import subprocess

from termcolor import colored
from collections import OrderedDict

import config
from utils import *
from normalize_tial_path import normalize_tial_path

global cluster_id
global username
global condor_dir
username = getpass.getuser()

def before_quit(verbose=True):
    if verbose:
        print('User requested termination, cleaning up')
    if cluster_id:
        if verbose:
            print()
            print(f'Remove job id = {cluster_id} from condor.')
            print()
        proc = subprocess.run(['condor_rm', str(cluster_id)])
    if not args.redirect:
        if verbose:
            print(f'Removing all temporary files in {condor_dir}')
        remove_files_in_dir(condor_dir)
        if verbose:
            print('Wait 1 seconds for NFS sync ...')
        time.sleep(2)


def exit_gracefully(signum, frame):
    # restore the original signal handler as otherwise evil things will happen
    # in raw_input when CTRL+C is pressed, and our signal handler is not re-entrant
    signal.signal(signal.SIGINT, original_sigint)
    try:
        before_quit()
        sys.exit(1)

    except KeyboardInterrupt:
        print()
        print("Ok ok, quitting")
        before_quit(verbose=False)
        print()
        sys.exit(1)

    # restore the exit gracefully handler here
    signal.signal(signal.SIGINT, exit_gracefully)

original_sigint = signal.getsignal(signal.SIGINT)
signal.signal(signal.SIGINT, exit_gracefully)

def run_job(args, condor_dir):
    condor_params = OrderedDict()

    pwd = normalize_tial_path(os.getcwd())
    condor_params = {
        'Universe': 'vanilla',
        'getenv': True,
        'initialdir': pwd,
        'notification': 'never',
        #'notify_user': f'{username}@uw.edu',
        'should_transfer_files': 'No',
        'periodic_remove': f'(RemoteWallClockTime - CumulativeSuspensionTime) > {args.time}',
        'coresize': 0,
        'request_cpus': args.cpu,
        'request_memory': int(args.mem * 1024),
    }


    # Exclude the machine heron
    if args.include:
        required_hosts = ' || '.join([f'TARGET.NikolaHost == "{node}"' for node in args.include])
        condor_params['requirements'] = required_hosts

    # GPU
    if args.gpu > 0:
        condor_params['+GPUJob'] = f"\"true\""
        condor_params['request_gpus'] = args.gpu

    if args.interactive:
        condor_params['nice_user'] = True
        submit_file_path = create_submit_file(condor_params, condor_dir)
        proc = subprocess.Popen(['condor_submit', '-interactive', submit_file_path])
        ret = proc.communicate()
    else:
        if args.nice_user:
            condor_params['nice_user'] = True

        stdout = os.path.join(condor_dir, 'stdout')
        stderr = os.path.join(condor_dir, 'stderr')
        condor_log  = os.path.join(condor_dir, 'condor_log')

        if not args.batch_job:
            cmd, cmd_exists = get_executable_cmd(args.cmd[0])
            if not cmd_exists:
                sys.exit(f'[Error] {cmd} doesn\'t exist')
            arguments = ' '.join(args.cmd[1:])
            condor_params['Executable'] = cmd
            condor_params['Arguments'] = arguments
            condor_params['Output'] = stdout
            condor_params['Error'] = stderr
        else:
            scripts, job_name = create_scripts_for_batch_jobs(args.cmd[0])
            script_path = os.path.join(condor_dir, 'script')
            for i, script in enumerate(scripts):
                with open(f'{script_path}.{i}', 'w') as f:
                    print(script, file=f)
            condor_params['Executable'] = '/usr/bin/bash'
            condor_params['Arguments'] = f'{script_path}.$(Index)'
            condor_params['Output'] = f'{stdout}.$(ProcId)'
            condor_params['Error'] = f'{stderr}.$(ProcId)'
            condor_params['Environment'] = 'PROCESS_ID=$(ProcId)'
        condor_params['Log'] = condor_log

        if args.job_name:
            condor_params['JobBatchName'] = args.job_name
        elif args.batch_job and job_name:
            condor_params['JobBatchName'] = job_name

        submit = htcondor.Submit(condor_params)
        schedd = htcondor.Schedd()          # get the Python representation of the scheduler
        global cluster_id
        cluster_id = None

        with schedd.transaction() as txn:   # open a transaction, represented by `txn`
            if args.batch_job:
                #results = submit.queue_with_itemdata(txn, 1, iter(itemdata))     # queues one job in the current transaction; returns job's ClusterID
                # itemdata must be a iter object
                results = submit.queue_with_itemdata(txn, 1, iter([{'Index': str(i)} for i in range(len(scripts))])) # queues one job in the current transaction; returns job's ClusterID
                cluster_id = results.cluster()
                num_jobs = len(scripts)
            else:
                cluster_id = submit.queue(txn)     # queues one job in the current transaction; returns job's ClusterID
                num_jobs = 1

        print(f'Submiting {num_jobs} job(s). ClusterID = {cluster_id} ...')
        time_now = datetime.datetime.now()
        time_delta = datetime.timedelta(days=args.day, hours=args.hr)
        due = time_now + time_delta
        print(f'This cluster will be removed at {due.strftime("%c")} ({args.day} days and {args.hr} hours from now).')

        proc = subprocess.Popen(['condor_wait', condor_log, str(cluster_id)])
        ret = proc.communicate()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        prog='rrun',
        description='Run computing jobs.',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        '-t',
        dest='time',
        type=str,
        default="3-0",
        help='Time limit for the request (days-hours), default is 3 day. If you use interactive mode, the time limit will be 12 hours to prevent people from forgetting to exit.'
    )
    parser.add_argument(
        '-c',
        dest='cpu',
        type=int,
        default=1,
        help='Number of CPU cores to request.'
    )
    parser.add_argument(
        '-m',
        dest='mem',
        type=float,
        default=config.mem_min,
        help=('Size of RAM (in GB) to request. If not specified, the memory size will be '
              'automatically decided according to free memory size of available nodes.')
    )
    parser.add_argument(
        '-G',
        dest='gpu',
        action='count',
        help=('Request a GPU. Set multiple times (ex: -GG) to request '
              'multiple GPUs.'
        )
    )
    # TODO
    #parser.add_argument(
    #    '-g', dest='gpu_type', default=None, choices=config.gpu_models,
    #    help=(f'Type of GPU to request. If not set, any type of GPU may be allocated. '
    #          f'Valid types: {",".join(config.gpu_models)}.'
    #          )
    #)
    parser.add_argument(
        '-N',
        '--nodes',
        dest='nodes',
        default=None,
        help=(f'Restrict the request to a specific set of nodes. '
              f'This should be a comma-separated list of node names. '
              f'It is NOT guaranteed all listed machines are available. '
              f'For availability, please refer to the command '
              f'{colored("rnode", "red")}. '
              f'Machines: {", ".join([colored(n, "green") for n in get_node_names()])}')
    )
    parser.add_argument(
        '-X',
        '--exclude',
        dest='exclude',
        default=None,
        help=('Restrict the request not to use a specific set of nodes. '
              'This should be a comma-separated list of node names.')
    )
    parser.add_argument(
        '-ND',
        '--no_desktop',
        dest='no_desktop',
        action='store_true',
        help='Restrict the request not to submit the job to desktop machines.'
    )
    parser.add_argument(
        '-r',
        dest='redirect',
        type=str,
        default=None,
        help=('The stdout, stderr, condor log and submit description files '
             'will be redirect to the assigned directory.')
    )
    parser.add_argument(
        '--overwrite',
        dest='overwrite',
        action='store_true',
        help='Overwrite redirected directory'
    )
    #parser.add_argument(
    #    '--itemdata_path',
    #    dest='itemdata_path',
    #    type=str,
    #    default=None,
    #    help='',
    #)
    # TODO
    #parser.add_argument(
    #    '-n', dest='job_name', default=None,
    #    help=('The job name which will be shown in the job list (hjob). '
    #          'Will be set to the full command (ex: python train.py -lr 0.01) if not specified.')
    #)
    #parser.add_argument(
    #    '-e', dest='email_notification', default='Error', choices=['Error', 'Complete'],
    #    help=('Owners of jobs are notified by e-mail when certain events occur. '
    #          'If defined by Complete (the default), the owner will be notified '
    #          'when the job terminates. If defined by Error, the owner will only '
    #          'be notified if the job terminates abnormally, or if the job is placed '
    #          'on hold because of a failure, and not by user request.')
    #)
    parser.add_argument(
        '-i',
        '--interactive',
        dest='interactive',
        action='store_true',
        help=('Create a interactive session for debugging. You will ssh to the '
              'assigned machine automatically. You will be a nice user if you '
              'use the interactive mode; people will have higher priority if '
              'they want to launch a job in the same machine.')
    )
    parser.add_argument(
        '-b',
        '--batch_job',
        dest='batch_job',
        action='store_true',
        help=('Run multiple jobs by a single command.'
              'Please assign a yaml file that describe the jobs you want to run.'
              'See the example.yaml for example.')
    )
    parser.add_argument(
        '-j'
        '--job_name',
        dest='job_name',
        type=str,
        default=None,
        help='It is intended for use by users to give meaningful names to their jobs'
    )
    parser.add_argument(
        '-n',
        '--nice_user',
        dest='nice_user',
        action='store_true',
        help=('You will be a nice user if you turn on this flag. '
              'Please use this flag if your job is not very urgent.')
    )
    parser.add_argument(
        'cmd',
        nargs=argparse.REMAINDER,
        metavar='',
        help='the command to launch your job.'
    )

    args = parser.parse_args()

    if not args.batch_job:
        if args.interactive == False and len(args.cmd) == 0:
            sys.exit(f'Error: Requires a command.')
    else:
        if len(args.cmd) == 0:
            sys.exit(f'Error: Requires a single yaml file.')
        elif len(args.cmd) > 1:
            sys.exit(f'Error: Requires a single yaml file. Too many files')

    # Check CPU and GPU values
    if not config.cpu_min <= args.cpu <= config.cpu_max:
        sys.exit(f'Error: Requested number of CPU ({args.cpu}) is out of range '
                 f'({config.cpu_min}-{config.cpu_max}).')
    if args.mem is not None and not config.mem_min <= args.mem <= config.mem_max:
        sys.exit(f'Error: Requested memory size ({args.mem:.2f} GB) is out of range '
                 f'({config.mem_min}-{config.mem_max}).')

    # Check time 
    args.day, args.hr = map(int, re.split('-+', args.time, maxsplit=1))
    if args.day > 10:
        sys.exit(f'Error: Requested time limit ({args.day}) is over time limit (10 days)')
    if args.hr >= 24:
        sys.exit(f'Error: Illegal hours (0 <= hr < 24)')

    args.time = args.day * 24 * 3600 + args.hr * 3600

    if args.interactive:
        args.time = 6 * 3600

    # Check GPU number and types
    if args.gpu is None:
        args.gpu = 0
        # TODO
        #args.gpu = 1 if args.gpu_type is not None else 0
    if args.gpu > 0:
        if args.gpu > config.gpu_max:
            sys.exit(f'Error: Requested number of GPU ({args.gpu}) is out of range '
                     f'({0}-{config.gpu_max}).')

    # TODO
    # if args.gpu_type is not None:
        # avail_types = set(config.gpu_models)
        # if args.gpu_type  not in avail_types:
            # sys.exit(f'Error: {gpu} is not a valid GPU type.')

    nodes = get_node_names()
    exclude = set()
    # Parse exclude
    if args.exclude is not None:
        exclude |= set(args.exclude.split(','))

    # Parse Nodes
    if args.nodes is not None:
        for n in args.nodes.split(','):
            if n not in nodes:
                sys.exit(f'Error: The node should be one of those: {", ".join(nodes)}')
        exclude |= (set(nodes) - set(args.nodes.split(',')))

    if args.no_desktop:
        exclude |= (desktop_hostnames | gpu_hostnames)

    args.include = list(set(nodes) - exclude)
    if exclude:
        for n in args.include:
            if n in config.gpu_node2gpu_max: 
                if args.gpu == 0:
                    sys.exit(f'Error: If you want to use {colored(n, "red")}, you have to turn on the -G flag.')
                if args.gpu > config.gpu_node2gpu_max[n]:
                    sys.exit(f'Error: You request {args.gpu} GPUs but {colored(n, "red")} only has {config.gpu_node2gpu_max[n]} GPUs.')
    elif args.gpu == 0:
        args.include = list(set(nodes) - set(config.gpu_node2gpu_max.keys()))
    else:
        args.include = None

    if args.redirect:
        condor_dir = normalize_tial_path(args.redirect)
        os.makedirs(condor_dir, exist_ok=args.overwrite)
        print('stdout, stderr, condor log files will be put in the directory:', condor_dir)
    else:
        os.makedirs('.rrun', exist_ok=True)
        tmpdir_prefix = normalize_tial_path(f'/homes/{username}/.rrun/')
        tmpdir = tempfile.TemporaryDirectory(prefix=tmpdir_prefix)
        condor_dir = tmpdir.name
        print('stdout, stderr, condor log files will be put in the temporary directory:', condor_dir)
        print('If you want to keep stdout, stderr and condor log, please use -r to redirect files.')
    run_job(args, condor_dir)

    if not args.redirect:
        remove_files_in_dir(condor_dir)

    print('Sucessful! Job finished!')
